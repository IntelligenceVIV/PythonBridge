{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['asdf', 'fjdk', 'afed', 'fjek', 'asdf', 'foo']\n",
      "['asdf', ' ', 'fjdk', ';', 'afed', ',', 'fjek', ',', 'asdf', ',', 'foo']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['asdf', 'fjdk', 'afed', 'fjek', 'asdf', 'foo']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 你需要将一个字符串分割为多个字段，但是分隔符(还有周围的空格)并不是固定的\n",
    "line = 'asdf fjdk; afed, fjek,asdf, foo'\n",
    "import re\n",
    "# 分隔符可以是逗号，分号或者是空格\n",
    "print(re.split(r'[;,\\s]\\s*', line))\n",
    "fields = re.split(r'(;|,|\\s)\\s*', line)\n",
    "print(fields)\n",
    "# 如果你不想保留分割字符串到结果列表中去\n",
    "# 但仍然需要使用到括号来分组正则表达式的话， 确保你的分组是非捕获分组\n",
    "re.split(r'(?:,|;|\\s)\\s*', line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 字符串开头或结尾匹配\n",
    "# 你需要通过指定的文本模式去检查字符串的开头或者结尾，比如文件名后缀，URL Scheme等等\n",
    "# 检查字符串开头或结尾的一个简单方法是使用 str.startswith() 或者是 str.endswith() 方法\n",
    "filename = 'spam.txt'\n",
    "filename.endswith('.txt')\n",
    "url = 'http://www.python.org'\n",
    "url.startswith('http:')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['.ipynb_checkpoints', '字符串和文本.ipynb', '数据结构和算法.ipynb']\n",
      "[]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "filenames = os.listdir('.')\n",
    "print(filenames)\n",
    "l = [name for name in filenames if name.endswith(('.c', '.h')) ]\n",
    "print(l)\n",
    "any(name.endswith('.py') for name in filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlopen\n",
    "\n",
    "def read_data(name):\n",
    "    if name.startswith(('http:', 'https:', 'ftp:')):\n",
    "        return urlopen(name).read()\n",
    "    else:\n",
    "        with open(name) as f:\n",
    "            return f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Dat1.csv', 'Dat2.csv']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 用Shell通配符匹配字符串\n",
    "# fnmatch 模块提供了两个函数—— fnmatch() 和 fnmatchcase() ，可以用来实现这样的匹配\n",
    "from fnmatch import fnmatch, fnmatchcase\n",
    "fnmatch('foo.txt', '*.txt')\n",
    "names = ['Dat1.csv', 'Dat2.csv', 'config.ini', 'foo.py']\n",
    "[name for name in names if fnmatch(name, 'Dat*.csv')]\n",
    "# fnmatch() 函数使用底层操作系统的大小写敏感规则(不同的系统是不一样的)来匹配模式\n",
    "# On Windows\n",
    "fnmatch('foo.txt', '*.TXT')\n",
    "# 如果你对这个区别很在意，可以使用 fnmatchcase() 来代替。它完全使用你的模式大小写匹配\n",
    "fnmatchcase('foo.txt', '*.TXT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['5412 N CLARK ST', '1060 W ADDISON ST', '2122 N CLARK ST'] ['5412 N CLARK ST']\n"
     ]
    }
   ],
   "source": [
    "addresses = [\n",
    "    '5412 N CLARK ST',\n",
    "    '1060 W ADDISON ST',\n",
    "    '1039 W GRANVILLE AVE',\n",
    "    '2122 N CLARK ST',\n",
    "    '4802 N BROADWAY',\n",
    "]\n",
    "from fnmatch import fnmatchcase\n",
    "a = [addr for addr in addresses if fnmatchcase(addr, '* ST')]\n",
    "b = [addr for addr in addresses if fnmatchcase(addr, '54[0-9][0-9] *CLARK*')]\n",
    "print(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yes\n",
      "yes\n"
     ]
    }
   ],
   "source": [
    "# 字符串匹配和搜索\n",
    "# 你想匹配或者搜索特定模式的文本\n",
    "text = 'yeah, but no, but yeah, but no, but yeah'\n",
    "text.find('no')\n",
    "# 对于复杂的匹配需要使用正则表达式和 re 模块\n",
    "text1 = '11/27/2012'\n",
    "import re\n",
    "if re.match(r'\\d+/\\d+/\\d+', text1):\n",
    "    print('yes')\n",
    "else:\n",
    "    print('no')\n",
    "# 如果你想使用同一个模式去做多次匹配，你应该先将模式字符串预编译为模式对象\n",
    "datepat = re.compile(r'\\d+/\\d+/\\d+')\n",
    "if datepat.match(text1):\n",
    "    print('yes')\n",
    "else:\n",
    "    print('no')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/27/2012 11 27 2012\n",
      "('11', '27', '2012')\n",
      "('3', '13', '2013')\n"
     ]
    }
   ],
   "source": [
    "# match() 总是从字符串开始去匹配，\n",
    "# 如果你想查找字符串任意部分的模式出现位置， 使用 findall() 方法去代替\n",
    "text = 'Today is 11/27/2012. PyCon starts 3/13/2013.'\n",
    "datepat = re.compile(r'\\d+/\\d+/\\d+')\n",
    "datepat.findall(text)\n",
    "# 通常会利用括号去捕获分组\n",
    "datepat = re.compile(r'(\\d+)/(\\d+)/(\\d+)')\n",
    "m = datepat.match('11/27/2012')\n",
    "print(m.group(0), m.group(1), m.group(2), m.group(3))\n",
    "month, day, year = m.groups()\n",
    "# 如果你想以迭代方式返回匹配，可以使用 finditer() 方法来代替\n",
    "for m in datepat.finditer(text):\n",
    "    print(m.groups())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'yep, but no, but yep, but no, but yep'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 字符串搜索和替换\n",
    "# 你想在字符串中搜索和匹配指定的文本模式\n",
    "text = 'yeah, but no, but yeah, but no, but yeah'\n",
    "text.replace('yeah', 'yep')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Today is 2012-11-27. PyCon starts 2013-3-13.'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = 'Today is 11/27/2012. PyCon starts 3/13/2013.'\n",
    "import re\n",
    "re.sub(r'(\\d+)/(\\d+)/(\\d+)', r'\\3-\\1-\\2', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Today is 2012-11-27. PyCon starts 2013-3-13. 2\n"
     ]
    }
   ],
   "source": [
    "# 对于更加复杂的替换，可以传递一个替换回调函数来代替\n",
    "from calendar import month_abbr\n",
    "def change_date(m):\n",
    "    mon_name = month_abbr[int(m.group(1))]\n",
    "    return '{} {} {}'.format(m.group(2), mon_name, m.group(3))\n",
    "datepat.sub(change_date, text)\n",
    "# 如果除了替换后的结果外，你还想知道有多少替换发生了\n",
    "newtext, n = datepat.subn(r'\\3-\\1-\\2', text)\n",
    "print(newtext, n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['PYTHON', 'python', 'Python']\n",
      "UPPER snake, lower snake, Mixed snake\n"
     ]
    }
   ],
   "source": [
    "# 需要以忽略大小写的方式搜索与替换文本字符串\n",
    "text = 'UPPER PYTHON, lower python, Mixed Python'\n",
    "# 为了在文本操作时忽略大小写，你需要在使用 re 模块的时候给这些操作提供 re.IGNORECASE 标志参数\n",
    "s = re.findall('python', text, flags=re.IGNORECASE)\n",
    "print(s)\n",
    "v = re.sub('python', 'snake', text, flags=re.IGNORECASE)\n",
    "print(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UPPER SNAKE, lower snake, Mixed Snake\n"
     ]
    }
   ],
   "source": [
    "# 最后的那个例子揭示了一个小缺陷，替换字符串并不会自动跟被匹配字符串的大小写保持一致\n",
    "def matchcase(word):\n",
    "    def replace(m):\n",
    "        text = m.group()\n",
    "        if text.isupper():\n",
    "            return word.upper()\n",
    "        elif text.islower():\n",
    "            return word.lower()\n",
    "        elif text[0].isupper():\n",
    "            return word.capitalize()\n",
    "        else:\n",
    "            return word\n",
    "    return replace\n",
    "v = re.sub('python', matchcase('snake'), text, flags=re.IGNORECASE)\n",
    "print(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['no.', 'yes.']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 最短匹配模式\n",
    "# 你正在试着用正则表达式匹配某个文本模式，但是它找到的是模式的最长可能匹配\n",
    "# 而你想修改它变成查找最短的可能匹配\n",
    "str_pat = re.compile(r'\"(.*)\"')\n",
    "text1 = 'Computer says \"no.\"'\n",
    "str_pat.findall(text1)\n",
    "# 在正则表达式中*操作符是贪婪的，因此匹配操作会查找最长的可能匹配\n",
    "text2 = 'Computer says \"no.\" Phone says \"yes.\"'\n",
    "str_pat.findall(text2)\n",
    "# 为了修正这个问题，可以在模式中的*操作符后面加上?修饰符\n",
    "str_pat = re.compile(r'\"(.*?)\"')\n",
    "str_pat.findall(text2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' this is a\\nmultiline comment ']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 多行匹配模式\n",
    "# 你正在试着使用正则表达式去匹配一大块的文本，而你需要跨越多行去匹配\n",
    "# 点(.)不能匹配换行符的事实\n",
    "comment = re.compile(r'/\\*(.*?)\\*/')\n",
    "text1 = '/* this is a comment */'\n",
    "text2 = '''/* this is a\n",
    "multiline comment */'''\n",
    "comment.findall(text1)\n",
    "comment.findall(text2)\n",
    "# 为了修正这个问题，你可以修改模式字符串，增加对换行的支持\n",
    "comment = re.compile(r'/\\*((?:.|\\n)*?)\\*/')\n",
    "comment.findall(text2)\n",
    "# re.compile() 函数接受一个标志参数叫 re.DOTALL，它可以让正则表达式中的点(.)匹配包括换行符在内的任意字符\n",
    "comment = re.compile(r'/\\*(.*?)\\*/', re.DOTALL)\n",
    "comment.findall(text2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spicy Jalapeño Spicy Jalapeño\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 将Unicode文本标准化\n",
    "# 你正在处理Unicode字符串，需要确保所有字符串在底层有相同的表示\n",
    "s1 = 'Spicy Jalape\\u00f1o'\n",
    "s2 = 'Spicy Jalapen\\u0303o'\n",
    "print(s1, s2)\n",
    "s1 == s2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "'Spicy Jalape\\xf1o'\n"
     ]
    }
   ],
   "source": [
    "# 可以使用unicodedata模块先将文本标准化\n",
    "import unicodedata\n",
    "t1 = unicodedata.normalize('NFC', s1)\n",
    "t2 = unicodedata.normalize('NFC', s2)\n",
    "print(t1 == t2)\n",
    "print(ascii(t1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "re.compile('[\\u0600-ۿݐ-ݿࢠ-ࣿ]+')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'STRASSE'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  在正则式中使用Unicode\n",
    "import re\n",
    "num = re.compile('\\d+')\n",
    "num.match('123')\n",
    "num.match('\\u0661\\u0662\\u0663')\n",
    "arabic = re.compile('[\\u0600-\\u06ff\\u0750-\\u077f\\u08a0-\\u08ff]+')\n",
    "print(arabic)\n",
    "pat = re.compile('stra\\u00dfe', re.IGNORECASE)\n",
    "s = 'straße'\n",
    "pat.match(s)\n",
    "pat.match(s.upper())\n",
    "s.upper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hello'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 删除字符串中不需要的字符\n",
    "# 你想去掉文本字符串开头，结尾或者中间不想要的字符，比如空白\n",
    "s = ' hello world \\n'\n",
    "s.strip()\n",
    "s.lstrip()\n",
    "s.rstrip()\n",
    "t = '-----hello====='\n",
    "t.lstrip('_')\n",
    "t.strip('-=')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hello world'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = ' hello     world \\n'\n",
    "s = s.strip()\n",
    "import re\n",
    "re.sub('\\s+', ' ', s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'pýtĥöñ is awesome\\n'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 审查清理文本字符串\n",
    "s = 'pýtĥöñ\\fis\\tawesome\\r\\n'\n",
    "remap = {ord('\\t') : ' ',ord('\\f') : ' ',ord('\\r') : None}\n",
    "a = s.translate(remap)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pýtĥöñ is awesome\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "610"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import unicodedata\n",
    "import sys\n",
    "cmb_chrs = dict.fromkeys(c for c in range(sys.maxunicode) if unicodedata.combining(chr(c)))\n",
    "b = unicodedata.normalize('NFD', a)\n",
    "print(b)\n",
    "b.translate(cmb_chrs)\n",
    "digitmap = { c: ord('0') + unicodedata.digit(chr(c)) for c in range(sys.maxunicode) if unicodedata.category(chr(c)) == 'Nd' }\n",
    "len(digitmap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'     Hello      World'"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 你想通过某种对齐方式来格式化字符串\n",
    "# 对于基本的字符串对齐操作，可以使用字符串的 ljust() , rjust() 和 center() 方法\n",
    "text = 'Hello World'\n",
    "text.ljust(20)\n",
    "text.rjust(20)\n",
    "text.center(20)\n",
    "text.rjust(20,'=')\n",
    "text.center(20,'*')\n",
    "# 函数 format() 同样可以用来很容易的对齐字符串\n",
    "# 你要做的就是使用 <,> 或者 ^ 字符后面紧跟一个指定的宽度\n",
    "format(text, '>20')\n",
    "format(text, '<20')\n",
    "format(text, '^20')\n",
    "format(text, '=>20s')\n",
    "format(text, '*^20s')\n",
    "'{:>10s} {:>10s}'.format('Hello', 'World')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is Chicago Not Chicago?\n",
      "Is Chicago Not Chicago?\n"
     ]
    }
   ],
   "source": [
    "# 想将几个小的字符串合并为一个大的字符串\n",
    "parts = ['Is', 'Chicago', 'Not', 'Chicago?']\n",
    "' '.join(parts)\n",
    "','.join(parts)\n",
    "a = 'Is Chicago'\n",
    "b = 'Not Chicago?'\n",
    "print(a + ' ' + b)\n",
    "print('{} {}'.format(a,b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Guido has 37 messages.'"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 字符串中插入变量\n",
    "s = '{name} has {n} messages.'\n",
    "s.format(name='Guido', n=37)\n",
    "# format 和 format_map() 的一个缺陷就是它们并不能很好的处理变量缺失的情况"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Guido has 37 messages.'"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name = 'Guido'\n",
    "n = 37\n",
    "import string\n",
    "s = string.Template('$name has $n messages.')\n",
    "s.substitute(vars())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Look into my eyes, look into my eyes, the eyes, the eyes, the eyes,\n",
      "not around the eyes, don't look around the eyes, look into my eyes,\n",
      "you're under.\n",
      "Look into my eyes, look into my eyes,\n",
      "the eyes, the eyes, the eyes, not around\n",
      "the eyes, don't look around the eyes,\n",
      "look into my eyes, you're under.\n",
      "    Look into my eyes, look into my\n",
      "eyes, the eyes, the eyes, the eyes, not\n",
      "around the eyes, don't look around the\n",
      "eyes, look into my eyes, you're under.\n",
      "Look into my eyes, look into my eyes,\n",
      "    the eyes, the eyes, the eyes, not\n",
      "    around the eyes, don't look around\n",
      "    the eyes, look into my eyes, you're\n",
      "    under.\n"
     ]
    }
   ],
   "source": [
    "# 你有一些长字符串，想以指定的列宽将它们重新格式化\n",
    "s = \"Look into my eyes, look into my eyes, the eyes, the eyes, \\\n",
    "the eyes, not around the eyes, don't look around the eyes, \\\n",
    "look into my eyes, you're under.\"\n",
    "import textwrap\n",
    "print(textwrap.fill(s, 70))\n",
    "print(textwrap.fill(s, 40))\n",
    "print(textwrap.fill(s, 40, initial_indent='    '))\n",
    "print(textwrap.fill(s, 40, subsequent_indent='    '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "120"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# textwrap 模块对于字符串打印是非常有用的，特别是当你希望输出自动匹配终端大小的时候\n",
    "# 你可以使用 os.get_terminal_size() 方法来获取终端的大小尺寸\n",
    "import os\n",
    "os.get_terminal_size().columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elements are written as \"<tag>text</tag>\".\n",
      "Elements are written as &quot;&lt;tag&gt;text&lt;/tag&gt;&quot;.\n",
      "Elements are written as \"&lt;tag&gt;text&lt;/tag&gt;\".\n"
     ]
    }
   ],
   "source": [
    "# 在字符串中处理html和xml\n",
    "# 你想将HTML或者XML实体如 &entity; 或 &#code; 替换为对应的文本\n",
    "# 再者，你需要转换文本中特定的字符(比如<, >, 或 &)\n",
    "s = 'Elements are written as \"<tag>text</tag>\".'\n",
    "import html\n",
    "print(s) # Elements are written as \"<tag>text</tag>\".\n",
    "print(html.escape(s)) # Elements are written as &quot;&lt;tag&gt;text&lt;/tag&gt;&quot;.\n",
    "# Disable escaping of quotes\n",
    "print(html.escape(s, quote=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'Spicy Jalape&#241;o'"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = 'Spicy Jalapeño'\n",
    "s.encode('ascii', errors='xmlcharrefreplace')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<re.Match object; span=(0, 3), match='foo'>"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 你有一个字符串，想从左至右将其解析为一个令牌流\n",
    "text = 'foo = 23 + 42 * 10'\n",
    "tokens = [('NAME', 'foo'), ('EQ','='), ('NUM', '23'), ('PLUS','+'),\n",
    "          ('NUM', '42'), ('TIMES', '*'), ('NUM', '10')]\n",
    "import re\n",
    "NAME = r'(?P<NAME>[a-zA-Z_][a-zA-Z_0-9]*)'\n",
    "NUM = r'(?P<NUM>\\d+)'\n",
    "PLUS = r'(?P<PLUS>\\+)'\n",
    "TIMES = r'(?P<TIMES>\\*)'\n",
    "EQ = r'(?P<EQ>=)'\n",
    "WS = r'(?P<WS>\\s+)'\n",
    "\n",
    "master_pat = re.compile('|'.join([NAME, NUM, PLUS, TIMES, EQ, WS]))\n",
    "scanner = master_pat.scanner('foo = 42')\n",
    "scanner.match() # <_sre.SRE_Match object at 0x100677738>\n",
    "# _.lastgroup, _.group() # ('NAME', 'foo')\n",
    "# scanner.match() # <_sre.SRE_Match object at 0x100677738>\n",
    "# _.lastgroup, _.group() # ('WS', ' ')\n",
    "# scanner.match() # <_sre.SRE_Match object at 0x100677738>\n",
    "# _.lastgroup, _.group() # ('EQ', '=')\n",
    "# scanner.match() # <_sre.SRE_Match object at 0x100677738>\n",
    "# _.lastgroup, _.group() # ('WS', ' ')\n",
    "# scanner.match() # <_sre.SRE_Match object at 0x100677738>\n",
    "# _.lastgroup, _.group() # ('NUM', '42')\n",
    "# scanner.match()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token(type='NAME', value='foo')\n",
      "Token(type='WS', value=' ')\n",
      "Token(type='EQ', value='=')\n",
      "Token(type='WS', value=' ')\n",
      "Token(type='NUM', value='42')\n",
      "\n",
      "Token(type='NAME', value='foo')\n",
      "Token(type='EQ', value='=')\n",
      "Token(type='NUM', value='23')\n",
      "Token(type='PLUS', value='+')\n",
      "Token(type='NUM', value='42')\n",
      "Token(type='TIMES', value='*')\n",
      "Token(type='NUM', value='10')\n"
     ]
    }
   ],
   "source": [
    "from collections import namedtuple\n",
    "def generate_tokens(pat, text):\n",
    "    Token = namedtuple('Token', ['type', 'value'])\n",
    "    scanner = pat.scanner(text)\n",
    "    for m in iter(scanner.match, None):\n",
    "        yield Token(m.lastgroup, m.group())\n",
    "\n",
    "# Example use\n",
    "for tok in generate_tokens(master_pat, 'foo = 42'):\n",
    "    print(tok)\n",
    "# Produces output\n",
    "# Token(type='NAME', value='foo')\n",
    "# Token(type='WS', value=' ')\n",
    "# Token(type='EQ', value='=')\n",
    "# Token(type='WS', value=' ')\n",
    "# Token(type='NUM', value='42')\n",
    "print()\n",
    "# 如果你想过滤令牌流，你可以定义更多的生成器函数或者使用一个生成器表达式\n",
    "tokens = (tok for tok in generate_tokens(master_pat, text)\n",
    "          if tok.type != 'WS')\n",
    "for tok in tokens:\n",
    "    print(tok)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token(type='PRINT', value='print')\n",
      "Token(type='NAME', value='er')\n"
     ]
    }
   ],
   "source": [
    "LT = r'(?P<LT><)'\n",
    "LE = r'(?P<LE><=)'\n",
    "EQ = r'(?P<EQ>=)'\n",
    "\n",
    "master_pat = re.compile('|'.join([LE, LT, EQ])) # Correct\n",
    "# master_pat = re.compile('|'.join([LT, LE, EQ])) # Incorrect\n",
    "PRINT = r'(?P<PRINT>print)'\n",
    "NAME = r'(?P<NAME>[a-zA-Z_][a-zA-Z_0-9]*)'\n",
    "\n",
    "master_pat = re.compile('|'.join([PRINT, NAME]))\n",
    "\n",
    "for tok in generate_tokens(master_pat, 'printer'):\n",
    "    print(tok)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "5\n",
      "14\n",
      "37\n"
     ]
    }
   ],
   "source": [
    "# 实现一个简单的递归下降分析器\n",
    "# 你想根据一组语法规则解析文本并执行命令，或者构造一个代表输入的抽象语法树\n",
    "# 如果语法非常简单，你可以不去使用一些框架，而是自己写这个解析器\n",
    "#!/usr/bin/env python\n",
    "# -*- encoding: utf-8 -*-\n",
    "\"\"\"\n",
    "Topic: 下降解析器\n",
    "Desc :\n",
    "\"\"\"\n",
    "import re\n",
    "import collections\n",
    "\n",
    "# Token specification\n",
    "NUM = r'(?P<NUM>\\d+)'\n",
    "PLUS = r'(?P<PLUS>\\+)'\n",
    "MINUS = r'(?P<MINUS>-)'\n",
    "TIMES = r'(?P<TIMES>\\*)'\n",
    "DIVIDE = r'(?P<DIVIDE>/)'\n",
    "LPAREN = r'(?P<LPAREN>\\()'\n",
    "RPAREN = r'(?P<RPAREN>\\))'\n",
    "WS = r'(?P<WS>\\s+)'\n",
    "\n",
    "master_pat = re.compile('|'.join([NUM, PLUS, MINUS, TIMES,\n",
    "                                  DIVIDE, LPAREN, RPAREN, WS]))\n",
    "# Tokenizer\n",
    "Token = collections.namedtuple('Token', ['type', 'value'])\n",
    "\n",
    "\n",
    "def generate_tokens(text):\n",
    "    scanner = master_pat.scanner(text)\n",
    "    for m in iter(scanner.match, None):\n",
    "        tok = Token(m.lastgroup, m.group())\n",
    "        if tok.type != 'WS':\n",
    "            yield tok\n",
    "\n",
    "\n",
    "# Parser\n",
    "class ExpressionEvaluator:\n",
    "    '''\n",
    "    Implementation of a recursive descent parser. Each method\n",
    "    implements a single grammar rule. Use the ._accept() method\n",
    "    to test and accept the current lookahead token. Use the ._expect()\n",
    "    method to exactly match and discard the next token on on the input\n",
    "    (or raise a SyntaxError if it doesn't match).\n",
    "    '''\n",
    "\n",
    "    def parse(self, text):\n",
    "        self.tokens = generate_tokens(text)\n",
    "        self.tok = None  # Last symbol consumed\n",
    "        self.nexttok = None  # Next symbol tokenized\n",
    "        self._advance()  # Load first lookahead token\n",
    "        return self.expr()\n",
    "\n",
    "    def _advance(self):\n",
    "        'Advance one token ahead'\n",
    "        self.tok, self.nexttok = self.nexttok, next(self.tokens, None)\n",
    "\n",
    "    def _accept(self, toktype):\n",
    "        'Test and consume the next token if it matches toktype'\n",
    "        if self.nexttok and self.nexttok.type == toktype:\n",
    "            self._advance()\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "\n",
    "    def _expect(self, toktype):\n",
    "        'Consume next token if it matches toktype or raise SyntaxError'\n",
    "        if not self._accept(toktype):\n",
    "            raise SyntaxError('Expected ' + toktype)\n",
    "\n",
    "    # Grammar rules follow\n",
    "    def expr(self):\n",
    "        \"expression ::= term { ('+'|'-') term }*\"\n",
    "        exprval = self.term()\n",
    "        while self._accept('PLUS') or self._accept('MINUS'):\n",
    "            op = self.tok.type\n",
    "            right = self.term()\n",
    "            if op == 'PLUS':\n",
    "                exprval += right\n",
    "            elif op == 'MINUS':\n",
    "                exprval -= right\n",
    "        return exprval\n",
    "\n",
    "    def term(self):\n",
    "        \"term ::= factor { ('*'|'/') factor }*\"\n",
    "        termval = self.factor()\n",
    "        while self._accept('TIMES') or self._accept('DIVIDE'):\n",
    "            op = self.tok.type\n",
    "            right = self.factor()\n",
    "            if op == 'TIMES':\n",
    "                termval *= right\n",
    "            elif op == 'DIVIDE':\n",
    "                termval /= right\n",
    "        return termval\n",
    "\n",
    "    def factor(self):\n",
    "        \"factor ::= NUM | ( expr )\"\n",
    "        if self._accept('NUM'):\n",
    "            return int(self.tok.value)\n",
    "        elif self._accept('LPAREN'):\n",
    "            exprval = self.expr()\n",
    "            self._expect('RPAREN')\n",
    "            return exprval\n",
    "        else:\n",
    "            raise SyntaxError('Expected NUMBER or LPAREN')\n",
    "\n",
    "\n",
    "def descent_parser():\n",
    "    e = ExpressionEvaluator()\n",
    "    print(e.parse('2'))\n",
    "    print(e.parse('2 + 3'))\n",
    "    print(e.parse('2 + 3 * 4'))\n",
    "    print(e.parse('2 + (3 + 4) * 5'))\n",
    "    # print(e.parse('2 + (3 + * 4)'))\n",
    "    # Traceback (most recent call last):\n",
    "    #    File \"<stdin>\", line 1, in <module>\n",
    "    #    File \"exprparse.py\", line 40, in parse\n",
    "    #    return self.expr()\n",
    "    #    File \"exprparse.py\", line 67, in expr\n",
    "    #    right = self.term()\n",
    "    #    File \"exprparse.py\", line 77, in term\n",
    "    #    termval = self.factor()\n",
    "    #    File \"exprparse.py\", line 93, in factor\n",
    "    #    exprval = self.expr()\n",
    "    #    File \"exprparse.py\", line 67, in expr\n",
    "    #    right = self.term()\n",
    "    #    File \"exprparse.py\", line 77, in term\n",
    "    #    termval = self.factor()\n",
    "    #    File \"exprparse.py\", line 97, in factor\n",
    "    #    raise SyntaxError(\"Expected NUMBER or LPAREN\")\n",
    "    #    SyntaxError: Expected NUMBER or LPAREN\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    descent_parser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bytearray(b'Hello Cruel World')"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 你想在字节字符串上执行普通的文本操作(比如移除，搜索和替换)\n",
    "data = b'Hello World'\n",
    "data[0:5] # b'Hello'\n",
    "data.startswith(b'Hello') # True\n",
    "data.split() # [b'Hello', b'World']\n",
    "data.replace(b'Hello', b'Hello Cruel')\n",
    "# 这些操作同样也适用于字节数组\n",
    "data = bytearray(b'Hello World') \n",
    "data[0:5] # bytearray(b'Hello')\n",
    "data.startswith(b'Hello') # True\n",
    "data.split() # [bytearray(b'Hello'), bytearray(b'World')]\n",
    "data.replace(b'Hello', b'Hello Cruel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "101"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 字节字符串的索引操作返回整数而不是单独字符\n",
    "b = b'Hello World' # Byte string\n",
    "b[0] # 72\n",
    "b[1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
